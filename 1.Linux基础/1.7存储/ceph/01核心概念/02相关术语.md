### Ceph术语

本术语表中的术语旨在解释说明`Ceph`现有的技术术语。

- `cephx`：`Ceph`认证协议，操作类似`Kerberos`，但不存在单点故障情况
- `Ceph`平台：所有`Ceph`软件
- `Ceph`堆栈：`Ceph`的两种或多种组件的集合
- 集群映射：包括`MON`映射、`OSD`映射、`PG`映射、`MDS`映射和`CRUSH`映射
- `Ceph对象存储`：由`Ceph`存储集群和`Ceph`对象网关组成
- `RGW`：`Ceph`的`S3/Swift`网关组件
- `RBD`：`Ceph`块存储组件
- `Ceph块存储`：用于与`librbd`、管理程序（如`QEMU`或`Xen`）和管理程序抽象层（如`libvirt`）结合使用
- `Ceph文件系统`：`Ceph`的`POSIX`文件系统组件
- `OSD`：物理或逻辑存储单元(如LUN)。有时，`Ceph`用户使用术语`OSD`来指代`Ceph OSD`守护进程，尽管正确的术语是`Ceph OSD`
- `Ceph OSD`：`Ceph OSD`守护进程，与逻辑盘(`OSD`)交互。
- `OSD id`：定义`OSD`的整数。它由监视器生成，作为创建新`OSD`的一部分
- `OSD fsid`：这是一个唯一标识符，用于进一步提高`OSD`的唯一性，它可以在`OSD`路径中的`osd_fsid`文件中找到。这个`fsid`术语可以与`uuid`互换使用
- `OSD uuid`：与`OSD fsid`一样，这是`OSD`唯一标识符，可以与`OSD fsid`互换使用
- `bluestore`：`OSD BlueStore`是`OSD`守护程序（kraken和更新版本）的新后端。与`filestore`不同，它直接将对象存储在`Ceph`块设备上，而不需要任何文件系统接口
- `filestore`：`OSD`守护进程的后端，需要日志记录、将文件写入文件系统
- `MON`：`Ceph`监控软件
- `MGR`：`Ceph`管理器软件，收集集群所有状态
- `MDS`：`Ceph`元数据服务
- `Ceph Client`：可以访问`Ceph`存储集群的`Ceph`组件的集合。组件包括`Ceph`对象网关、`Ceph`块设备、`Ceph`文件系统以及它们相应的库、内核模块、用户空间文件系统
- `Ceph Kernel Modules`：内核模块的集合，可以用来与`Ceph`系统交互(例如，`Ceph.ko`, `rbd.ko`)。
- `Ceph Client Libraries`：可用于与`Ceph`系统组件交互的库集合
- `Ceph Release`：任何明显编号的`Ceph`版本
- `Ceph Point Release`：任何只包含错误或安全修正的特别发行版
- `Ceph Interim Release`：`Ceph`的版本尚未通过质量保证测试，但可能包含新特性
- `Ceph Release Candidate`：`Ceph`的一个主要版本，已经经历了最初的质量保证测试，并且已经为`beta`测试做好了准备
- `Ceph Stable Release`：`Ceph`的主要版本，其中所有来自前一个临时版本的特性都成功地通过了质量保证测试
- `Teuthology`：在`Ceph`上执行脚本测试的软件集合
- `CRUSH`：可伸缩散列下的受控复制(Controlled Replication Under Scalable Hashing)。这是`Ceph`用来计算对象存储位置的算法
- `CRUSH rule`：适用于特定池的压缩数据放置规则
- `Pools`：池是用于存储对象的逻辑分区
- `systemd oneshot`：一种`systemd`类型，其中一个命令定义在`ExecStart`中，它将在完成时退出(它不打算后台化)
- `LVM tags`：用于`LVM`卷和组的可扩展元数据。它用于存储关于设备及其与`osd`的关系的特定于`c